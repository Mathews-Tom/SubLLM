{
  "cli_version": "0.4.2",
  "checkpoint_id": "4d668b4f0f4b",
  "strategy": "manual-commit",
  "branch": "feat/enhance-examples",
  "checkpoints_count": 7,
  "files_touched": [
    "examples/basic_usage.py",
    "examples/openai_proxy.py"
  ],
  "sessions": [
    {
      "metadata": "/4d/668b4f0f4b/0/metadata.json",
      "transcript": "/4d/668b4f0f4b/0/full.jsonl",
      "context": "/4d/668b4f0f4b/0/context.md",
      "content_hash": "/4d/668b4f0f4b/0/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/0/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/1/metadata.json",
      "transcript": "/4d/668b4f0f4b/1/full.jsonl",
      "context": "/4d/668b4f0f4b/1/context.md",
      "content_hash": "/4d/668b4f0f4b/1/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/1/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/2/metadata.json",
      "transcript": "/4d/668b4f0f4b/2/full.jsonl",
      "context": "/4d/668b4f0f4b/2/context.md",
      "content_hash": "/4d/668b4f0f4b/2/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/2/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/3/metadata.json",
      "transcript": "/4d/668b4f0f4b/3/full.jsonl",
      "context": "/4d/668b4f0f4b/3/context.md",
      "content_hash": "/4d/668b4f0f4b/3/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/3/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/4/metadata.json",
      "transcript": "/4d/668b4f0f4b/4/full.jsonl",
      "context": "/4d/668b4f0f4b/4/context.md",
      "content_hash": "/4d/668b4f0f4b/4/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/4/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/5/metadata.json",
      "transcript": "/4d/668b4f0f4b/5/full.jsonl",
      "context": "/4d/668b4f0f4b/5/context.md",
      "content_hash": "/4d/668b4f0f4b/5/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/5/prompt.txt"
    },
    {
      "metadata": "/4d/668b4f0f4b/6/metadata.json",
      "transcript": "/4d/668b4f0f4b/6/full.jsonl",
      "context": "/4d/668b4f0f4b/6/context.md",
      "content_hash": "/4d/668b4f0f4b/6/content_hash.txt",
      "prompt": "/4d/668b4f0f4b/6/prompt.txt"
    }
  ],
  "token_usage": {
    "input_tokens": 21,
    "cache_creation_tokens": 192162,
    "cache_read_tokens": 159825,
    "output_tokens": 9,
    "api_call_count": 7
  }
}
